{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4fe557f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hex2bin(text):\n",
    "#     ret = ''\n",
    "#     for i in text:\n",
    "#         tmp = bin(int(i, 16))\n",
    "#         ret += '0'*(4-len(tmp)) + tmp\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a26fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c80dd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Mukul/Downloads/TrainingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e6b84014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3fa9e6ac4a36c66b8ca3887914c6c75b08dad9095f1d7a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21b7f56f644f02d51ae82c9d50f69fad686319657712d4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>74203af11b8bbb1d31ac34e85f3076588fbbf2dcf1a4f7...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6b412e99f1dea02c124a90b5f2cf29496cb84f2b2b33a0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5b84fb6fc7710b0e499394d9b406950d2436a118e2d867...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CID                                               Text  class\n",
       "0    0  3fa9e6ac4a36c66b8ca3887914c6c75b08dad9095f1d7a...      3\n",
       "1    1  21b7f56f644f02d51ae82c9d50f69fad686319657712d4...      2\n",
       "2    2  74203af11b8bbb1d31ac34e85f3076588fbbf2dcf1a4f7...      3\n",
       "3    3  6b412e99f1dea02c124a90b5f2cf29496cb84f2b2b33a0...      1\n",
       "4    4  5b84fb6fc7710b0e499394d9b406950d2436a118e2d867...      1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef3f0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2bin(string):\n",
    "    return bin(int(string, base=16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ac772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9cd6ccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hex2bin('12432096acd13432'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29f8e21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b1001001000011001000001001011010101100110100010011010000110010'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(int('12432096acd13432', base=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2883d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=data[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ad9f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2723a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0f85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e8490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712b3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d3a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6b3a8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=[]\n",
    "for i in range(len(data)):\n",
    "    gb.append(hex2bin(v[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c19fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f789120f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.38 GiB for an array with shape (80000,) and data type <U8002",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gb\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.38 GiB for an array with shape (80000,) and data type <U8002"
     ]
    }
   ],
   "source": [
    "gb=np.array(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97328a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3849704c",
   "metadata": {},
   "source": [
    "hj=len(gb[1])/4\n",
    "hj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b14dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a837896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values = ['number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a310242",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value=[]\n",
    "for i in range(80000):\n",
    "    index_value.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dee7009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=gb,index=index_value,columns=column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e5d4bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b11111110101001111001101010110001001010001101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b10000110110111111101010110111101100100010011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0b11101000010000000111010111100010001101110001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b11010110100000100101110100110011111000111011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b10110111000010011111011011011111100011101110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>0b10001000100000100001011010100100100000111000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>0b11100001000011111000011000101001101110100110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>0b11100100011011001100000101001110011011010101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>0b11001000101001011000111101100000010010100011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>0b10011000010010110101001010001011000000101011...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  number\n",
       "0      0b11111110101001111001101010110001001010001101...\n",
       "1      0b10000110110111111101010110111101100100010011...\n",
       "2      0b11101000010000000111010111100010001101110001...\n",
       "3      0b11010110100000100101110100110011111000111011...\n",
       "4      0b10110111000010011111011011011111100011101110...\n",
       "...                                                  ...\n",
       "79995  0b10001000100000100001011010100100100000111000...\n",
       "79996  0b11100001000011111000011000101001101110100110...\n",
       "79997  0b11100100011011001100000101001110011011010101...\n",
       "79998  0b11001000101001011000111101100000010010100011...\n",
       "79999  0b10011000010010110101001010001011000000101011...\n",
       "\n",
       "[80000 rows x 1 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b239f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "28fd713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(string,keyword):\n",
    "    return len(string.split(keyword))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "088e12eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count(df['number'][0],'01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "de0276fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((22,80000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "75015795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fcad840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=[]\n",
    "for i in range(64):\n",
    "    N.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42bee47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "89988b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['number']).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb26c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(df['number'])):\n",
    "#         a[i][0]=word_count(df['number'][i],'010')\n",
    "#         a[i][1]=word_count(df['number'][i],'0110')\n",
    "#         a[i][2]=word_count(df['number'][i],'01110')\n",
    "#         a[i][3]=word_count(df['number'][i],'011110')\n",
    "#         a[i][4]=word_count(df['number'][i],'0111110')\n",
    "#         a[i][5]=word_count(df['number'][i],'01111110')\n",
    "#         a[i][6]=word_count(df['number'][i],'011111110')\n",
    "#         a[i][7]=word_count(df['number'][i],'0111111110')\n",
    "#         a[i][8]=word_count(df['number'][i],'01111111110')\n",
    "#         a[i][9]=word_count(df['number'][i],'011111111110')\n",
    "#         a[i][10]=word_count(df['number'][i],'0111111111110')\n",
    "#         a[i][11]=word_count(df['number'][i],'01111111111110')\n",
    "#         a[i][12]=word_count(df['number'][i],'011111111111110')\n",
    "#         a[i][13]=word_count(df['number'][i],'0111111111111110')\n",
    "#         a[i][14]=word_count(df['number'][i],'01111111111111110')\n",
    "#         a[i][15]=word_count(df['number'][i],'011111111111111110')\n",
    "#         a[i][16]=word_count(df['number'][i],'0111111111111111110')\n",
    "#         a[i][17]=word_count(df['number'][i],'01111111111111111110')\n",
    "#         a[i][18]=word_count(df['number'][i],'011111111111111111110')\n",
    "#         a[i][19]=word_count(df['number'][i],'0111111111111111111110')\n",
    "#         a[i][20]=word_count(df['number'][i],'01111111111111111111110')\n",
    "#         a[i][21]=word_count(df['number'][i],'011111111111111111111110')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "17af7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(df['number'])):\n",
    "    a[0][i]=word_count(df['number'][i],'010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f366dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[757., 796., 779., ..., 814., 806., 775.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "825438e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['number'])):\n",
    "        a[0][i]=word_count(df['number'][i],'010')\n",
    "        a[1][i]=word_count(df['number'][i],'0110')\n",
    "        a[2][i]=word_count(df['number'][i],'01110')\n",
    "        a[3][i]=word_count(df['number'][i],'011110')\n",
    "        a[4][i]=word_count(df['number'][i],'0111110')\n",
    "        a[5][i]=word_count(df['number'][i],'01111110')\n",
    "        a[6][i]=word_count(df['number'][i],'011111110')\n",
    "        a[7][i]=word_count(df['number'][i],'0111111110')\n",
    "        a[8][i]=word_count(df['number'][i],'01111111110')\n",
    "        a[9][i]=word_count(df['number'][i],'011111111110')\n",
    "        a[10][i]=word_count(df['number'][i],'0111111111110')\n",
    "        a[11][i]=word_count(df['number'][i],'01111111111110')\n",
    "        a[12][i]=word_count(df['number'][i],'011111111111110')\n",
    "        a[13][i]=word_count(df['number'][i],'0111111111111110')\n",
    "        a[14][i]=word_count(df['number'][i],'01111111111111110')\n",
    "        a[15][i]=word_count(df['number'][i],'011111111111111110')\n",
    "        a[16][i]=word_count(df['number'][i],'0111111111111111110')\n",
    "        a[17][i]=word_count(df['number'][i],'01111111111111111110')\n",
    "        a[18][i]=word_count(df['number'][i],'011111111111111111110')\n",
    "        a[19][i]=word_count(df['number'][i],'0111111111111111111110')\n",
    "        a[20][i]=word_count(df['number'][i],'01111111111111111111110')\n",
    "        a[21][i]=word_count(df['number'][i],'011111111111111111111110')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e7350ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat=a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e2b971c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat=np.array(new_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "47417579",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_val=[]\n",
    "for i in range(22):\n",
    "    col_val.append('Distribution %d'%i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1503b91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Distribution 0',\n",
       " 'Distribution 1',\n",
       " 'Distribution 2',\n",
       " 'Distribution 3',\n",
       " 'Distribution 4',\n",
       " 'Distribution 5',\n",
       " 'Distribution 6',\n",
       " 'Distribution 7',\n",
       " 'Distribution 8',\n",
       " 'Distribution 9',\n",
       " 'Distribution 10',\n",
       " 'Distribution 11',\n",
       " 'Distribution 12',\n",
       " 'Distribution 13',\n",
       " 'Distribution 14',\n",
       " 'Distribution 15',\n",
       " 'Distribution 16',\n",
       " 'Distribution 17',\n",
       " 'Distribution 18',\n",
       " 'Distribution 19',\n",
       " 'Distribution 20',\n",
       " 'Distribution 21']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3fd4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(data=new_mat,index=index_value,columns=col_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2d825",
   "metadata": {},
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e30e694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distribution 0</th>\n",
       "      <th>Distribution 1</th>\n",
       "      <th>Distribution 2</th>\n",
       "      <th>Distribution 3</th>\n",
       "      <th>Distribution 4</th>\n",
       "      <th>Distribution 5</th>\n",
       "      <th>Distribution 6</th>\n",
       "      <th>Distribution 7</th>\n",
       "      <th>Distribution 8</th>\n",
       "      <th>Distribution 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Distribution 12</th>\n",
       "      <th>Distribution 13</th>\n",
       "      <th>Distribution 14</th>\n",
       "      <th>Distribution 15</th>\n",
       "      <th>Distribution 16</th>\n",
       "      <th>Distribution 17</th>\n",
       "      <th>Distribution 18</th>\n",
       "      <th>Distribution 19</th>\n",
       "      <th>Distribution 20</th>\n",
       "      <th>Distribution 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>812.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>786.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>807.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>814.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>806.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>775.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Distribution 0  Distribution 1  Distribution 2  Distribution 3  \\\n",
       "0               757.0           444.0           261.0           114.0   \n",
       "1               796.0           429.0           245.0           127.0   \n",
       "2               779.0           448.0           240.0           140.0   \n",
       "3               812.0           455.0           225.0           113.0   \n",
       "4               814.0           439.0           228.0           119.0   \n",
       "...               ...             ...             ...             ...   \n",
       "79995           786.0           419.0           246.0           141.0   \n",
       "79996           807.0           458.0           239.0           112.0   \n",
       "79997           814.0           457.0           226.0           127.0   \n",
       "79998           806.0           448.0           243.0           122.0   \n",
       "79999           775.0           436.0           268.0           115.0   \n",
       "\n",
       "       Distribution 4  Distribution 5  Distribution 6  Distribution 7  \\\n",
       "0                62.0            22.0            16.0             7.0   \n",
       "1                58.0            30.0            18.0            10.0   \n",
       "2                60.0            33.0            19.0             8.0   \n",
       "3                57.0            34.0            16.0            15.0   \n",
       "4                73.0            27.0            16.0             5.0   \n",
       "...               ...             ...             ...             ...   \n",
       "79995            58.0            33.0            15.0             9.0   \n",
       "79996            57.0            27.0            13.0             6.0   \n",
       "79997            66.0            29.0            15.0             7.0   \n",
       "79998            59.0            30.0            16.0             8.0   \n",
       "79999            72.0            33.0            20.0             8.0   \n",
       "\n",
       "       Distribution 8  Distribution 9  ...  Distribution 12  Distribution 13  \\\n",
       "0                 8.0             3.0  ...              2.0              1.0   \n",
       "1                 4.0             1.0  ...              0.0              0.0   \n",
       "2                 5.0             0.0  ...              0.0              0.0   \n",
       "3                 3.0             0.0  ...              2.0              0.0   \n",
       "4                 1.0             0.0  ...              0.0              1.0   \n",
       "...               ...             ...  ...              ...              ...   \n",
       "79995             6.0             1.0  ...              0.0              0.0   \n",
       "79996             4.0             5.0  ...              1.0              1.0   \n",
       "79997             6.0             3.0  ...              0.0              0.0   \n",
       "79998             0.0             1.0  ...              0.0              0.0   \n",
       "79999             0.0             0.0  ...              0.0              0.0   \n",
       "\n",
       "       Distribution 14  Distribution 15  Distribution 16  Distribution 17  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              1.0   \n",
       "...                ...              ...              ...              ...   \n",
       "79995              0.0              0.0              0.0              0.0   \n",
       "79996              0.0              0.0              0.0              0.0   \n",
       "79997              0.0              0.0              0.0              0.0   \n",
       "79998              0.0              0.0              0.0              0.0   \n",
       "79999              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       Distribution 18  Distribution 19  Distribution 20  Distribution 21  \n",
       "0                  0.0              0.0              0.0              0.0  \n",
       "1                  0.0              0.0              0.0              0.0  \n",
       "2                  0.0              0.0              0.0              0.0  \n",
       "3                  0.0              0.0              0.0              0.0  \n",
       "4                  0.0              0.0              0.0              0.0  \n",
       "...                ...              ...              ...              ...  \n",
       "79995              0.0              0.0              0.0              0.0  \n",
       "79996              0.0              0.0              0.0              0.0  \n",
       "79997              0.0              0.0              0.0              0.0  \n",
       "79998              0.0              0.0              0.0              0.0  \n",
       "79999              0.0              0.0              0.0              0.0  \n",
       "\n",
       "[80000 rows x 22 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ce83aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.concat([df1,data['class']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d00e9d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 23)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "006cca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss:  1.3911 train_accuracy:  0.2503 test_loss:  1.3925 test_accuracy:  0.2438\n",
      "epoch:  1 train_loss:  1.3948 train_accuracy:  0.251 test_loss:  1.3949 test_accuracy:  0.2479\n",
      "epoch:  2 train_loss:  1.3868 train_accuracy:  0.2506 test_loss:  1.3865 test_accuracy:  0.2528\n",
      "epoch:  3 train_loss:  1.3885 train_accuracy:  0.2524 test_loss:  1.3886 test_accuracy:  0.2528\n",
      "epoch:  4 train_loss:  1.3895 train_accuracy:  0.2502 test_loss:  1.3897 test_accuracy:  0.2504\n",
      "epoch:  5 train_loss:  1.3916 train_accuracy:  0.2515 test_loss:  1.3906 test_accuracy:  0.2491\n",
      "epoch:  6 train_loss:  1.3868 train_accuracy:  0.2503 test_loss:  1.3876 test_accuracy:  0.2427\n",
      "epoch:  7 train_loss:  1.3866 train_accuracy:  0.2512 test_loss:  1.387 test_accuracy:  0.2449\n",
      "epoch:  8 train_loss:  1.3866 train_accuracy:  0.2518 test_loss:  1.3867 test_accuracy:  0.2477\n",
      "epoch:  9 train_loss:  1.3864 train_accuracy:  0.2504 test_loss:  1.3864 test_accuracy:  0.2515\n",
      "epoch:  10 train_loss:  1.3868 train_accuracy:  0.2513 test_loss:  1.3873 test_accuracy:  0.2442\n",
      "epoch:  11 train_loss:  1.3865 train_accuracy:  0.2505 test_loss:  1.3862 test_accuracy:  0.2483\n",
      "epoch:  12 train_loss:  1.3871 train_accuracy:  0.2508 test_loss:  1.3873 test_accuracy:  0.2512\n",
      "epoch:  13 train_loss:  1.3864 train_accuracy:  0.2481 test_loss:  1.3863 test_accuracy:  0.2544\n",
      "epoch:  14 train_loss:  1.3865 train_accuracy:  0.2503 test_loss:  1.3865 test_accuracy:  0.2499\n",
      "epoch:  15 train_loss:  1.3865 train_accuracy:  0.2503 test_loss:  1.3865 test_accuracy:  0.2504\n",
      "epoch:  16 train_loss:  1.3866 train_accuracy:  0.2487 test_loss:  1.3866 test_accuracy:  0.253\n",
      "epoch:  17 train_loss:  1.3864 train_accuracy:  0.2521 test_loss:  1.3865 test_accuracy:  0.2456\n",
      "epoch:  18 train_loss:  1.3866 train_accuracy:  0.2505 test_loss:  1.387 test_accuracy:  0.2451\n",
      "epoch:  19 train_loss:  1.3865 train_accuracy:  0.2513 test_loss:  1.3868 test_accuracy:  0.2442\n",
      "epoch:  20 train_loss:  1.3864 train_accuracy:  0.2483 test_loss:  1.3862 test_accuracy:  0.2536\n",
      "epoch:  21 train_loss:  1.3864 train_accuracy:  0.2513 test_loss:  1.3867 test_accuracy:  0.2442\n",
      "epoch:  22 train_loss:  1.3864 train_accuracy:  0.2483 test_loss:  1.3862 test_accuracy:  0.2535\n",
      "epoch:  23 train_loss:  1.3864 train_accuracy:  0.2538 test_loss:  1.3865 test_accuracy:  0.2476\n",
      "epoch:  24 train_loss:  1.3864 train_accuracy:  0.2513 test_loss:  1.3866 test_accuracy:  0.2442\n",
      "epoch:  25 train_loss:  1.3864 train_accuracy:  0.2483 test_loss:  1.3862 test_accuracy:  0.2537\n",
      "epoch:  26 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  27 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  28 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  29 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  30 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  31 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  32 train_loss:  1.3863 train_accuracy:  0.2483 test_loss:  1.3863 test_accuracy:  0.2537\n",
      "epoch:  33 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  34 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  35 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  36 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3866 test_accuracy:  0.2442\n",
      "epoch:  37 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  38 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  39 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  40 train_loss:  1.3864 train_accuracy:  0.2503 test_loss:  1.3862 test_accuracy:  0.2517\n",
      "epoch:  41 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  42 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  43 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  44 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  45 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  46 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  47 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  48 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  49 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  50 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  51 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  52 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3866 test_accuracy:  0.2442\n",
      "epoch:  53 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  54 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  55 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3862 test_accuracy:  0.2517\n",
      "epoch:  56 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  57 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  58 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  59 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  60 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  61 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  62 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  63 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  64 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3866 test_accuracy:  0.2442\n",
      "epoch:  65 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  66 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  67 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  68 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  69 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  70 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  71 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  72 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  73 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  74 train_loss:  1.3863 train_accuracy:  0.2483 test_loss:  1.3863 test_accuracy:  0.2537\n",
      "epoch:  75 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  76 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  77 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  78 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  79 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  80 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  81 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  82 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  83 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  84 train_loss:  1.3864 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  85 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  86 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  87 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  88 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  89 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  90 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  91 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  92 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  93 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  94 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  95 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  96 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  97 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  98 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  99 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  100 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  101 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  102 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  103 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  104 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  105 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  106 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  107 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  108 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  109 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  110 train_loss:  1.3864 train_accuracy:  0.2503 test_loss:  1.3862 test_accuracy:  0.2517\n",
      "epoch:  111 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  112 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  113 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  114 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  115 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  116 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  117 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  118 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  119 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  120 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  121 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  122 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  123 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  124 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  125 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  126 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  127 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  128 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  129 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  130 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  131 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  132 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  133 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  134 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  135 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  136 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  137 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  138 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  139 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  140 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  141 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  142 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  143 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  144 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  145 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  146 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  147 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  148 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  149 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  150 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  151 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  152 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  153 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  154 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  155 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  156 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  157 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  158 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  159 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  160 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  161 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  162 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  163 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  164 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  165 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  166 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  167 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  168 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  169 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  170 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  171 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  172 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  173 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  174 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  175 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3862 test_accuracy:  0.2517\n",
      "epoch:  176 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  177 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  178 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  179 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  180 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  181 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  182 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  183 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  184 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3865 test_accuracy:  0.2442\n",
      "epoch:  185 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  186 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  187 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3864 test_accuracy:  0.2517\n",
      "epoch:  188 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  189 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  190 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  191 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  192 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  193 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3864 test_accuracy:  0.2504\n",
      "epoch:  194 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  195 train_loss:  1.3863 train_accuracy:  0.2503 test_loss:  1.3863 test_accuracy:  0.2517\n",
      "epoch:  196 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n",
      "epoch:  197 train_loss:  1.3863 train_accuracy:  0.2502 test_loss:  1.3863 test_accuracy:  0.2504\n",
      "epoch:  198 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3864 test_accuracy:  0.2442\n",
      "epoch:  199 train_loss:  1.3863 train_accuracy:  0.2513 test_loss:  1.3863 test_accuracy:  0.2442\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = np.array(df3[\"class\"])\n",
    "X = np.array(df3.drop([\"class\"],axis=1))\n",
    "train_x,test_x,train_y,test_y=train_test_split(X,Y)\n",
    "train_x = torch.from_numpy(train_x).type(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).type(torch.int64)\n",
    "test_x = torch.from_numpy(test_x).type(torch.float32)\n",
    "test_y = torch.from_numpy(test_y).type(torch.LongTensor)\n",
    "\n",
    "batch = 5\n",
    "no_of_batches = len(df3)//batch\n",
    "epochs = 200\n",
    "\n",
    "train_ds = TensorDataset(train_x,train_y)\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=batch,shuffle=True)\n",
    "test_ds = TensorDataset(test_x,test_y)\n",
    "\n",
    "test_dl = DataLoader(test_ds,batch_size=batch)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.liner_1 = nn.Linear(22,22)\n",
    "        \n",
    "        self.liner_2 = nn.Linear(22,22)\n",
    "        \n",
    "        self.liner_3 = nn.Linear(22,22)\n",
    "        self.liner_4 = nn.Linear(22,22)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \n",
    "        x = F.relu(self.liner_1(input))\n",
    "        \n",
    "        x = F.relu(self.liner_2(x))\n",
    "        \n",
    "        x = F.relu(self.liner_3(x))\n",
    "        x = self.liner_4(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    \n",
    "    y_pred = torch.argmax(y_pred,dim=1)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "train_loss=[]\n",
    "train_acc=[]\n",
    "test_loss=[]\n",
    "test_acc=[]\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    model = Model()\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    return model,opt\n",
    "\n",
    "model,optim = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "      \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x),train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data\n",
    "        epoch_test_accuracy = accuracy(model(test_x),test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data\n",
    "        print('epoch: ',epoch,'train_loss: ',round(epoch_loss.item(),4),'train_accuracy: ',round(epoch_accuracy.item(),4),\n",
    "             'test_loss: ',round(epoch_test_loss.item(),4),'test_accuracy: ',round(epoch_test_accuracy.item(),4)\n",
    "              )\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_accuracy)\n",
    "\n",
    "plt.plot(range(1,epochs+1),train_loss,label='train_loss')\n",
    "plt.plot(range(1,epochs+1),test_loss,label='test_loss')\n",
    "plt.plot(range(1,epochs+1),train_acc,label='train_acc')\n",
    "plt.plot(range(1,epochs+1),test_acc,label='test_acc')\n",
    "plt.show()\n",
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b4fcb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vb=np.array(df3['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb68ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vbb = df3.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d47068de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distribution 0</th>\n",
       "      <th>Distribution 1</th>\n",
       "      <th>Distribution 2</th>\n",
       "      <th>Distribution 3</th>\n",
       "      <th>Distribution 4</th>\n",
       "      <th>Distribution 5</th>\n",
       "      <th>Distribution 6</th>\n",
       "      <th>Distribution 7</th>\n",
       "      <th>Distribution 8</th>\n",
       "      <th>Distribution 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Distribution 12</th>\n",
       "      <th>Distribution 13</th>\n",
       "      <th>Distribution 14</th>\n",
       "      <th>Distribution 15</th>\n",
       "      <th>Distribution 16</th>\n",
       "      <th>Distribution 17</th>\n",
       "      <th>Distribution 18</th>\n",
       "      <th>Distribution 19</th>\n",
       "      <th>Distribution 20</th>\n",
       "      <th>Distribution 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>812.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>786.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>807.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>814.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>806.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>775.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Distribution 0  Distribution 1  Distribution 2  Distribution 3  \\\n",
       "0               757.0           444.0           261.0           114.0   \n",
       "1               796.0           429.0           245.0           127.0   \n",
       "2               779.0           448.0           240.0           140.0   \n",
       "3               812.0           455.0           225.0           113.0   \n",
       "4               814.0           439.0           228.0           119.0   \n",
       "...               ...             ...             ...             ...   \n",
       "79995           786.0           419.0           246.0           141.0   \n",
       "79996           807.0           458.0           239.0           112.0   \n",
       "79997           814.0           457.0           226.0           127.0   \n",
       "79998           806.0           448.0           243.0           122.0   \n",
       "79999           775.0           436.0           268.0           115.0   \n",
       "\n",
       "       Distribution 4  Distribution 5  Distribution 6  Distribution 7  \\\n",
       "0                62.0            22.0            16.0             7.0   \n",
       "1                58.0            30.0            18.0            10.0   \n",
       "2                60.0            33.0            19.0             8.0   \n",
       "3                57.0            34.0            16.0            15.0   \n",
       "4                73.0            27.0            16.0             5.0   \n",
       "...               ...             ...             ...             ...   \n",
       "79995            58.0            33.0            15.0             9.0   \n",
       "79996            57.0            27.0            13.0             6.0   \n",
       "79997            66.0            29.0            15.0             7.0   \n",
       "79998            59.0            30.0            16.0             8.0   \n",
       "79999            72.0            33.0            20.0             8.0   \n",
       "\n",
       "       Distribution 8  Distribution 9  ...  Distribution 12  Distribution 13  \\\n",
       "0                 8.0             3.0  ...              2.0              1.0   \n",
       "1                 4.0             1.0  ...              0.0              0.0   \n",
       "2                 5.0             0.0  ...              0.0              0.0   \n",
       "3                 3.0             0.0  ...              2.0              0.0   \n",
       "4                 1.0             0.0  ...              0.0              1.0   \n",
       "...               ...             ...  ...              ...              ...   \n",
       "79995             6.0             1.0  ...              0.0              0.0   \n",
       "79996             4.0             5.0  ...              1.0              1.0   \n",
       "79997             6.0             3.0  ...              0.0              0.0   \n",
       "79998             0.0             1.0  ...              0.0              0.0   \n",
       "79999             0.0             0.0  ...              0.0              0.0   \n",
       "\n",
       "       Distribution 14  Distribution 15  Distribution 16  Distribution 17  \\\n",
       "0                  0.0              0.0              0.0              0.0   \n",
       "1                  0.0              0.0              0.0              0.0   \n",
       "2                  0.0              0.0              0.0              0.0   \n",
       "3                  0.0              0.0              0.0              0.0   \n",
       "4                  0.0              0.0              0.0              1.0   \n",
       "...                ...              ...              ...              ...   \n",
       "79995              0.0              0.0              0.0              0.0   \n",
       "79996              0.0              0.0              0.0              0.0   \n",
       "79997              0.0              0.0              0.0              0.0   \n",
       "79998              0.0              0.0              0.0              0.0   \n",
       "79999              0.0              0.0              0.0              0.0   \n",
       "\n",
       "       Distribution 18  Distribution 19  Distribution 20  Distribution 21  \n",
       "0                  0.0              0.0              0.0              0.0  \n",
       "1                  0.0              0.0              0.0              0.0  \n",
       "2                  0.0              0.0              0.0              0.0  \n",
       "3                  0.0              0.0              0.0              0.0  \n",
       "4                  0.0              0.0              0.0              0.0  \n",
       "...                ...              ...              ...              ...  \n",
       "79995              0.0              0.0              0.0              0.0  \n",
       "79996              0.0              0.0              0.0              0.0  \n",
       "79997              0.0              0.0              0.0              0.0  \n",
       "79998              0.0              0.0              0.0              0.0  \n",
       "79999              0.0              0.0              0.0              0.0  \n",
       "\n",
       "[80000 rows x 22 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ae4c0739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e4fe6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree,metrics\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8f253ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.27      0.25      5033\n",
      "           1       0.26      0.25      0.25      5009\n",
      "           2       0.26      0.18      0.21      5073\n",
      "           3       0.25      0.31      0.27      4885\n",
      "\n",
      "    accuracy                           0.25     20000\n",
      "   macro avg       0.25      0.25      0.25     20000\n",
      "weighted avg       0.25      0.25      0.25     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abf = AdaBoostClassifier(n_estimators=50,learning_rate=1,random_state=1234)\n",
    "abf.fit(train_x,train_y)\n",
    "ypred=abf.predict(test_x)\n",
    "print(metrics.accuracy_score(test_y,ypred))\n",
    "print(metrics.classification_report(test_y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460a4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
